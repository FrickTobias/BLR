from snakemake.utils import validate

configfile: "blr.yaml"
validate(config, "config.schema.yaml")

# Import rules for trimming fastq files.
include: "rules/trim.smk"

# Import rules for phasing
include: "rules/phasing.smk"


rule final:
   input:
        "reads.1.final.fastq.gz",
        "reads.2.final.fastq.gz",
        "phasing_stats.txt",
        "multiqc_report.html"


rule fastqc_raw_reads:
    # Creates fastqc reports from raw read files. Output names are automatically given by fastqc.
    output:
        qc = expand("trimmed.barcoded.{nr}_fastqc.html", nr=(1,2)),
        zip = expand("trimmed.barcoded.{nr}_fastqc.zip", nr=(1,2))
    input:
        reads = expand("trimmed.barcoded.{nr}.fastq.gz", nr=(1,2)),
    log:
        "fastqc_raw_reads.log"
    shell:
        "fastqc"
        " {input.reads}"
        " 2> {log}"


rule multiqc_summarize:
    # Summarizes all reports into one html report. Automatically identifies input/gives output names but by adding
    # more input files it controls when snakemake runs the multiqc summary.
    output:
        multiqc_data_dir = directory("multiqc_data"),
        summarized_reports = "multiqc_report.html"
    input:
        raw_read_1_qc = "trimmed.barcoded.1_fastqc.html",
        raw_read_2_qc = "trimmed.barcoded.2_fastqc.html",
        bam = "mapped.sorted.tag.mkdup.bcmerge.mol.filt.bam"
    log:
        "multiqc.log"
    shell:
        "multiqc"
        " ."
        " 2> {log}"


rule starcode_clustering:
    # Cluster DBS barcodes using starcode
    output:
        "barcodes.clstr"
    input:
        "barcodes.fasta.gz"
    threads: 20
    log: "starcode_clustering.log"
    shell:
        "pigz -cd {input} |"
        " starcode"
        " -o {output}"
        " -t {threads}"
        " -d {config[barcode_max_dist]}"
        " --print-clusters"
        " 2> {log}"


rule barcode_sort_fastq:
    # Assumes barcode read name is followed by barcode sequence.
    # Exmaple: @ST-E00269:339:H27G2CCX2:7:1102:21186:8060:AAAAAAAATATCTACGCTCA BX:Z:AAAAAAAATATCTACGCTCA
    output:
        fastq = "sorted.{nr}.fastq.gz"
    input:
        fastq = "trimmed.barcoded.{nr}.fastq.gz"
    shell:
        "pigz -cd -p 1 {input.fastq} |"
        " paste - - - - |"
        " sort -t ' ' -k2 |"
        " tr '\t' '\n' |"
        " pigz > {output.fastq}"


rule map_reads:
    output:
        bam = "mapped.sorted.bam"
    input:
        r1_fastq = "trimmed.barcoded.1.fastq.gz" if config["read_mapper"] != "ema" else "sorted.1.fastq.gz",
        r2_fastq = "trimmed.barcoded.2.fastq.gz" if config["read_mapper"] != "ema" else "sorted.2.fastq.gz"
    threads: 20
    log: "read_mapping.log"
    run:
        commands = {
            "bwa":
                "bwa mem"
                " -t {threads}"
                " {config[genome_reference]}"
                " {input.r1_fastq}"
                " {input.r2_fastq}",
            "bowtie2":
                "bowtie2"
                " -p {threads}"
                " --reorder"
                " --maxins 2000"
                " -x {config[genome_reference]}"
                " -1 {input.r1_fastq}"
                " -2 {input.r2_fastq}",
            "minimap2":
                "minimap2"
                " -ax sr"
                " -t {threads}"
                " {config[genome_reference]}"
                " {input.r1_fastq}"
                " {input.r2_fastq}",
            "ema":
                "ema align"
                " -1 <(pigz -cd {input.r1_fastq})"
                " -2 <(pigz -cd {input.r2_fastq})"
                " -r {config[genome_reference]}"
                " -t {threads}"
                " -p 10x"
        }
        command = commands[config["read_mapper"]].format(**locals(), **globals())

        # Add duplicate marking to map_reads pipe if samblaster selected.
        mkdup = "samblaster |" if config["duplicate_marker"] == "samblaster" else ""

        shell(
            "{command} 2> >(tee {log} >&2) |"
            "{mkdup}"
            "samtools sort -"
            " -@ {threads}"
            " -O BAM > {output.bam}"
        )


rule tagbam:
    # Add barcodes to BAM files as SAM tags. Also adds a RG tag.
    output:
        bam = "mapped.sorted.tag.mkdup.bam" if config['duplicate_marker'] == 'samblaster' else "mapped.sorted.tag.bam"
    input:
        bam = "mapped.sorted.bam"
    log: "tag_bam.log"
    shell:
        "blr tagbam"
        " {input.bam}"
        " -o -"
        " 2> {log}"
        " | "
        "samtools addreplacerg"
        " -O BAM"
        " -r ID:1"
        " -r LB:lib1"
        " -r PU:unit1"
        " -r SM:20"
        " -r PL:ILLUMINA"
        " -"
        " 2>> {log} "
        " > {output.bam}"


rule mark_duplicates:
    output:
        bam = "mapped.sorted.tag.mkdup.bam"
    input:
        bam = "mapped.sorted.tag.bam"
    log: "mark_duplicates.log"
    threads: 20
    shell:
        "sambamba markdup"
        " -t {threads}"
        " {input.bam}"
        " {output.bam} 2> {log}"


rule clusterrmdup:
    # Removes cluster duplicates and indexes output
    output:
        bam = "mapped.sorted.tag.mkdup.bcmerge.bam",
        merges = "barcode-merges.csv"
    input:
        bam = "mapped.sorted.tag.mkdup.bam"
    log: "clusterrmdup.log"
    shell:
        "blr clusterrmdup"
        " {input.bam}"
        " {output.merges}"
        " -o {output.bam}"
        " -b {config[cluster_tag]} 2>> {log}"


rule buildmolecules:
    # Groups reads into molecules depending on their genomic position and barcode
    output:
        bam = "mapped.sorted.tag.mkdup.bcmerge.mol.bam",
        stats = expand("{stat}.tsv", stat=['molecules_per_bc', 'molecule_stats'])
    input:
        bam = "mapped.sorted.tag.mkdup.bcmerge.bam"
    log: "buildmolecules.log"
    shell:
        "blr buildmolecules"
        " {input.bam}"
        " -o {output.bam}"
        " --stats-files"
        " -m {config[molecule_tag]}"
        " -n {config[num_mol_tag]}"
        " -b {config[cluster_tag]}"
        " 2> {log}"


rule filterclusters:
    # Filter clusters based on parameters
    output:
        bam = "mapped.sorted.tag.mkdup.bcmerge.mol.filt.bam",
        bai = "mapped.sorted.tag.mkdup.bcmerge.mol.filt.bam.bai"
    input:
        bam = "mapped.sorted.tag.mkdup.bcmerge.mol.bam"
    log: "filterclusters.log"
    shell:
        "blr filterclusters"
        " {input.bam}"
        " -m {config[molecule_tag]}"
        " -n {config[num_mol_tag]}"
        " -b {config[cluster_tag]}"
        " -M {config[max_molecules_per_bc]}"
        " 2>> {log} |"
        " tee {output.bam} |"
        " samtools index  - {output.bai}"


rule bam_to_fastq:
    # Convert final BAM file to FASTQ files for read 1 and 2
    output:
        r1_fastq = "reads.1.final.fastq.gz",
        r2_fastq = "reads.2.final.fastq.gz"
    input:
        bam = "mapped.sorted.tag.mkdup.bcmerge.mol.filt.bam"
    log: "samtools-fastq.log"
    threads: 20
    shell:
        "samtools fastq"
        " -@ {threads}"
        " -T {config[cluster_tag]},{config[sequence_tag]}"
        " {input.bam}"
        " -1 {output.r1_fastq}"
        " -2 {output.r2_fastq} 2>> {log}"


rule symlink_reference_variants:
    output: "variants.reference.vcf"
    shell:
        "ln -s {config[reference_variants]} {output}"


rule recal_base_qual_scores:
    "Recalibrate base calling qualities"
    output:
        recal_table = "gatk_BQSR_table.txt"
    input:
        bam = "mapped.sorted.tag.mkdup.bcmerge.mol.filt.bam"
    log: "recal_base_qual_scores.log"
    shell:
        "gatk --java-options -Xmx{config[heap_space]}g BaseRecalibrator"
        " -R {config[genome_reference]}"
        " --known-sites {config[dbSNP]}"
        " -I {input.bam}"
        " -O {output.recal_table}"
        " 2> {log}"


rule apply_recal:
    "Adjusts bam file with results from gatk base score recalibration"
    output:
        recal_bam = "mapped.sorted.tag.mkdup.bcmerge.mol.filt.BQSR.bam"
    input:
        bam = "mapped.sorted.tag.mkdup.bcmerge.mol.filt.bam",
        recal_table = "gatk_BQSR_table.txt"
    log: "apply_recal.log"
    shell:
        "gatk --java-options -Xmx{config[heap_space]}g ApplyBQSR"
        " --bqsr-recal-file {input.recal_table}"
        " -R {config[genome_reference]}"
        " -I {input.bam}"
        " 2> {log}"
        " -O {output.recal_bam}"

rule index_bam_pre_variant_caller:
    output:
        bai = "mapped.sorted.tag.mkdup.bcmerge.mol.filt.BQSR.bam.bai"
    input:
        bam = "mapped.sorted.tag.mkdup.bcmerge.mol.filt.BQSR.bam"
    log: "index_bam_pre_variant_caller.log"
    shell:
        "samtools index"
        " {input.bam}"
        " {output.bai}"


rule call_variants:
    output:
         vcf = "variants.called.vcf"
    input:
         bam = "mapped.sorted.tag.mkdup.bcmerge.mol.filt.BQSR.bam" if config["BQSR"]
         else "mapped.sorted.tag.mkdup.bcmerge.mol.filt.bam",
         index = "mapped.sorted.tag.mkdup.bcmerge.mol.filt.BQSR.bam.bai" if config["BQSR"]
         else "mapped.sorted.tag.mkdup.bcmerge.mol.filt.bam.bai"
    log: "call_variants.log"
    run:
        commands = {
            "freebayes":
                 "freebayes"
                 " -f {config[genome_reference]}"
                 " {input.bam}"
                 " 2> {log}"
                 " | "
                 "vcffilter"
                 " -f"
                 " 'AC > 0'"
                 " 1> {output.vcf} 2>> {log}",
            "bcftools":
                "bcftools mpileup"
                " -f {config[genome_reference]}"
                " {input.bam}"
                " --threads {threads}"
                " 2> {log}"
                " | "
                "bcftools call"
                " -m"
                " -v"
                " -O v"
                " --ploidy GRCh38"
                " --threads {threads}"
                " -o {output.vcf} 2>> {log}",
            "gatk":
                "gatk --java-options -Xmx{config[heap_space]}g HaplotypeCaller"
                " -R {config[genome_reference]}"
                " -I {input.bam}"
                " -ERC GVCF"
                " -O {output.vcf} 2> {log}",
            # This option is currently not included in the pipeline documentation, but it will run on any system which
            # - runs Linux (it's not maintained for any other system)
            # - has deepvariant installed (e.g. through conda)
            # TODO: Add a conditional installation of deepvariant for Linux systems and add to pipeline docs.
            "deepvariant":
                "deepvariant"
	            " --model_type=WGS"
	            " --output_vcf={output.vcf}"
	            " --reads={input.bam}"
	            " --ref={config[genome_reference]}"
                }

        command = commands[config["variant_caller"]].format(**locals(), **globals())

        shell(
            "{command}"
        )
